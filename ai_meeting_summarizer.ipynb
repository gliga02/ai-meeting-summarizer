{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4CRmRlitiEXf",
    "outputId": "79ade902-309e-42d5-99ce-badc83adc378"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access is denied.\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers torchaudio librosa accelerate reportlab gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 386,
     "referenced_widgets": [
      "24d443587afd4d9b884df0842b2eeed3",
      "ca01c466fc9649078c7fde19e55b1f1b",
      "f06a0b8fe59f482b9868d4493e4048fb",
      "edd8875dcaaa4051b673e2de874e0b75",
      "95af08e65f3147e99be8b23d28e3d5ae",
      "e2b8c2fcfd9f4e798338632dd71cb7df",
      "64ce7be65bd64a2a8c1a170ec281ca13",
      "7917fc737bc34db99a7a3786991358a7",
      "9bc91f0af0ef4809ae8bb80c25a6db15",
      "03b1758eb0024c7681b72762f07ead89",
      "c6c80ad9e4ce4f57b1eb9ff16be63a7b",
      "7addbc9bfa5e405fad3a1fea1bb65819",
      "99585ff658f248978f87c1d6353727fb",
      "28994402b7d64da2a94f723683a5ecd1",
      "e18e0c2a4fdc45469487426990970001",
      "35fc841dde1c414c943d2bb164c4dcd4",
      "311baa5f1b2242d28dfec6a7127a6d21",
      "f7c50c06f93646e486241b4bc557bee0",
      "4cdc8c0b847b40cf9e97f916a1f6fc0b",
      "e8f8967c5e954c5582913c18f2ce2693",
      "d6df493b1810493992eb6e5a047d57af",
      "75f02f75df3f4ca09bbfcc766f189cec",
      "0789db728d33468f8b8cc584bde47df2",
      "479e01904bf44973acb27a4dbc6e9ff0",
      "acbb97dfc5e84ed5b3605ed940a0c1b9",
      "b26af3cf22974ad4b26961c5366ab5a4",
      "a2d4ab8df68f4d46910a81d81c827eed",
      "3b9aad7ba660413da548ba909b73043e",
      "71e61a2150bd47d8a95e120197da2944",
      "bbc4f5168ec74c8eb442ec04326838be",
      "cbf55a9377134d56ba243772a99e8333",
      "5b0d9bd17cb0451b873a75d3b717938d",
      "ba17ed77e52a4a4fbef10fb8c6ad664e",
      "6558d93fb21c4cd199c6ae758caef934",
      "775d3b13e751436c9d038d773c59eb5f",
      "a06bd0ca51dc427a946efac1177e385b",
      "eea5f8e36a1b46598c29a414342e3d62",
      "ff8f1cc771f140a685898bfbd5f1b01d",
      "72ea71689fdb40d1ae810fca7c131f48",
      "f33f3c9d13f64e7196c831edf513e658",
      "d8f909307e0c40e2af4073b98e7d1c91",
      "78d9cc29e9c24a67b0021505127bbc9e",
      "d623685ab18c461fbb640e124a103f31",
      "b13a0a3f83f84a088537f085447a554c",
      "5b244573b43c47be8a007bfe84d025f4",
      "3a059ef6489c49838150323ccfe3ff47",
      "5dfb81354e9c4b60a24ea75f1341e714",
      "bce4da1522d44be884eddb678093952b",
      "77205c87c24a4667bea5cc62f63e0b2b",
      "4d3adb61735b4420b7aab10bfc16b856",
      "c7017ef77cc6415797f3ec9970a5f9a4",
      "5e218bb489cd4111a9fccfbbbab02c7b",
      "81cf7a78d6ff4dfdacb0c793d2711b82",
      "aa97b68e119040f2a407297bad34e87d",
      "fb857f9302b641e2a2ebfddc2f55368e",
      "01f03821af2e4627b3c7fafba19d1e02",
      "912fce6255f24d0e9a03a9f25a9bbb3f",
      "cf7dafa053b746c4887caed85ae29952",
      "4da56c87de8d46108a6a0d2ec1400529",
      "1746f1baa9264c7d828fd01f6c1402cb",
      "527926ec76714817b0c54e2e1483cbba",
      "e05210d221984d4bb612f257d4fda2e8",
      "f33e4f506ef74b438d689c213d92d435",
      "cda0cf7bc76846ae8ac0641e004c3453",
      "dba748fc0a42452390edef570536d0a9",
      "5ec0923d7f3445149bb1d210c447491d",
      "e3035da419c64f5388f00839cc59e74a",
      "155f13c0f52c4175812eb49c1162c4dc",
      "fd895acc37cc4a4c93e299b507f628fc",
      "58e362692bba409ca0120a77304239ab",
      "9f86fe07442840e8b6291c5d4f04d796",
      "bb682103725f4b829025e382a78fc6f0",
      "3e6a233d5ca44ec9b9d34e8e911b606d",
      "1f31414efcf243e4bf530c134adccaaf",
      "296783cc77d34ee7b8b182ad908537a3",
      "e5c40c994fa242a08bd7477d27a3b0a7",
      "958c544ce62a4bd587913831805fa352",
      "e341e2fc00e74870b9228e0c5fb870e6",
      "0cee2a7ce4944f908c0be3dde9a34e7d",
      "60ec731220ce46808a04b2a8009188c4",
      "c2974985d6cf48e49627a65d0073248e",
      "a8ab1b272d4249b9a873b564195441ef",
      "e8895279a24b41ccb9d8cfef7c8374cf",
      "5cd9c334dcae4bce89a68b73886b98a4",
      "631d96c41f9f438180696a2e2fec4d72",
      "ca6ccb9edb714428a8b3b74c6ccede28",
      "aca55918beb244b283f3b3df591c02a4",
      "724da64457254dda99e6ca929a511fe5",
      "2dd829dd95b64cd0bcb590a11afe9d0e",
      "9645f56570464a78a7241ec049e59219",
      "eb821b0266ba425ab914fd53ac94704a",
      "1f2927fc12f84d1583f7d4c2758ecd62",
      "9310a2d4b131488d88e0e1e62612e3d0",
      "504385ff342b4b58aa42719c364da4e9",
      "e0a36e749f5d4fdc8dbf5db4e49b17f6",
      "9767cd8756904746a30d528ff9d73563",
      "09f03f2f75a44fff84cf04c10e3984ee",
      "a21b3cb8e7634698b21cc546fdaf4f14",
      "5add9bb61f7246d785a7716e71f7d2cb",
      "df485e07f712430e86bfc8c2032d695a",
      "18d688298dee454fa98aaa76b9e739b8",
      "a6af5f13dc684f6fbeb31929a6bcc61a",
      "cf5a0c3fa68349aca569ffe2ac29ef8b",
      "73b0ce9378884c36b41727af39210758",
      "8cc51e42cf4e4664a23085526d47852c",
      "5f1f30a4b3274d5aafcc8891bcadcec4",
      "7bb9339c4ef14129abab0349344be0d0",
      "e7375cdf6f7f4627b2212b04e4e17192",
      "afabadb605f54d16b18adcbc6d08c6d4",
      "e74474918a1b4c0086e67aef840ff033",
      "6bec5c23e86e42c2b37959cb500355cc",
      "93bdfc6e5c634f448d5cadad593d092f",
      "31655e066d3847ce9e11e3fd71defc17",
      "4bc5c8f3871d47ee8a449e8a9da5761e",
      "74ab31d03bb341708d68d4c0dc8758bd",
      "c9578c04bb5044fa97608e438f3d790f",
      "1a622fb37bba4619b7ed23f2d45ab947",
      "ed19a90ad828481ab054ce654526f680",
      "12256d15a93240d1ae7f60b00de63251",
      "efbba7817e0048669ad7a5619d23ef60",
      "eeaa51c15696403a80fc1fb7ef336d2a"
     ]
    },
    "id": "7dgDgWQwjEGg",
    "outputId": "902143b0-0921-4cf8-c606-ebd687f6fc5e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d443587afd4d9b884df0842b2eeed3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7addbc9bfa5e405fad3a1fea1bb65819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0789db728d33468f8b8cc584bde47df2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6558d93fb21c4cd199c6ae758caef934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b244573b43c47be8a007bfe84d025f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f03821af2e4627b3c7fafba19d1e02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3035da419c64f5388f00839cc59e74a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e341e2fc00e74870b9228e0c5fb870e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd829dd95b64cd0bcb590a11afe9d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df485e07f712430e86bfc8c2032d695a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bec5c23e86e42c2b37959cb500355cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "transcriber = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model = \"openai/whisper-small\",\n",
    "    device = 0,\n",
    ")\n",
    "\n",
    "def transcribe_audio(file_path):\n",
    "    \"\"\"\n",
    "    Transcribe audio file to text using Whisper model.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        str: Transcribed text.\n",
    "    \"\"\"\n",
    "    \n",
    "    transcription = transcriber(file_path)\n",
    "\n",
    "\n",
    "    text = transcription['text']\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "dBEhdxQEjULT",
    "outputId": "80d8a6ba-2fd3-45fb-e9ba-8c1ef65bccfc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-1421d5f2-5aad-4af8-8192-a31ead79d506\" name=\"files[]\" multiple disabled\n",
       "        style=\"border:none\" />\n",
       "     <output id=\"result-1421d5f2-5aad-4af8-8192-a31ead79d506\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script>// Copyright 2017 Google LLC\n",
       "//\n",
       "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
       "// you may not use this file except in compliance with the License.\n",
       "// You may obtain a copy of the License at\n",
       "//\n",
       "//      http://www.apache.org/licenses/LICENSE-2.0\n",
       "//\n",
       "// Unless required by applicable law or agreed to in writing, software\n",
       "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
       "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
       "// See the License for the specific language governing permissions and\n",
       "// limitations under the License.\n",
       "\n",
       "/**\n",
       " * @fileoverview Helpers for google.colab Python module.\n",
       " */\n",
       "(function(scope) {\n",
       "function span(text, styleAttributes = {}) {\n",
       "  const element = document.createElement('span');\n",
       "  element.textContent = text;\n",
       "  for (const key of Object.keys(styleAttributes)) {\n",
       "    element.style[key] = styleAttributes[key];\n",
       "  }\n",
       "  return element;\n",
       "}\n",
       "\n",
       "// Max number of bytes which will be uploaded at a time.\n",
       "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
       "\n",
       "function _uploadFiles(inputId, outputId) {\n",
       "  const steps = uploadFilesStep(inputId, outputId);\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  // Cache steps on the outputElement to make it available for the next call\n",
       "  // to uploadFilesContinue from Python.\n",
       "  outputElement.steps = steps;\n",
       "\n",
       "  return _uploadFilesContinue(outputId);\n",
       "}\n",
       "\n",
       "// This is roughly an async generator (not supported in the browser yet),\n",
       "// where there are multiple asynchronous steps and the Python side is going\n",
       "// to poll for completion of each step.\n",
       "// This uses a Promise to block the python side on completion of each step,\n",
       "// then passes the result of the previous step as the input to the next step.\n",
       "function _uploadFilesContinue(outputId) {\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  const steps = outputElement.steps;\n",
       "\n",
       "  const next = steps.next(outputElement.lastPromiseValue);\n",
       "  return Promise.resolve(next.value.promise).then((value) => {\n",
       "    // Cache the last promise value to make it available to the next\n",
       "    // step of the generator.\n",
       "    outputElement.lastPromiseValue = value;\n",
       "    return next.value.response;\n",
       "  });\n",
       "}\n",
       "\n",
       "/**\n",
       " * Generator function which is called between each async step of the upload\n",
       " * process.\n",
       " * @param {string} inputId Element ID of the input file picker element.\n",
       " * @param {string} outputId Element ID of the output display.\n",
       " * @return {!Iterable<!Object>} Iterable of next steps.\n",
       " */\n",
       "function* uploadFilesStep(inputId, outputId) {\n",
       "  const inputElement = document.getElementById(inputId);\n",
       "  inputElement.disabled = false;\n",
       "\n",
       "  const outputElement = document.getElementById(outputId);\n",
       "  outputElement.innerHTML = '';\n",
       "\n",
       "  const pickedPromise = new Promise((resolve) => {\n",
       "    inputElement.addEventListener('change', (e) => {\n",
       "      resolve(e.target.files);\n",
       "    });\n",
       "  });\n",
       "\n",
       "  const cancel = document.createElement('button');\n",
       "  inputElement.parentElement.appendChild(cancel);\n",
       "  cancel.textContent = 'Cancel upload';\n",
       "  const cancelPromise = new Promise((resolve) => {\n",
       "    cancel.onclick = () => {\n",
       "      resolve(null);\n",
       "    };\n",
       "  });\n",
       "\n",
       "  // Wait for the user to pick the files.\n",
       "  const files = yield {\n",
       "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
       "    response: {\n",
       "      action: 'starting',\n",
       "    }\n",
       "  };\n",
       "\n",
       "  cancel.remove();\n",
       "\n",
       "  // Disable the input element since further picks are not allowed.\n",
       "  inputElement.disabled = true;\n",
       "\n",
       "  if (!files) {\n",
       "    return {\n",
       "      response: {\n",
       "        action: 'complete',\n",
       "      }\n",
       "    };\n",
       "  }\n",
       "\n",
       "  for (const file of files) {\n",
       "    const li = document.createElement('li');\n",
       "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
       "    li.append(span(\n",
       "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
       "        `last modified: ${\n",
       "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
       "                                    'n/a'} - `));\n",
       "    const percent = span('0% done');\n",
       "    li.appendChild(percent);\n",
       "\n",
       "    outputElement.appendChild(li);\n",
       "\n",
       "    const fileDataPromise = new Promise((resolve) => {\n",
       "      const reader = new FileReader();\n",
       "      reader.onload = (e) => {\n",
       "        resolve(e.target.result);\n",
       "      };\n",
       "      reader.readAsArrayBuffer(file);\n",
       "    });\n",
       "    // Wait for the data to be ready.\n",
       "    let fileData = yield {\n",
       "      promise: fileDataPromise,\n",
       "      response: {\n",
       "        action: 'continue',\n",
       "      }\n",
       "    };\n",
       "\n",
       "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
       "    let position = 0;\n",
       "    do {\n",
       "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
       "      const chunk = new Uint8Array(fileData, position, length);\n",
       "      position += length;\n",
       "\n",
       "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
       "      yield {\n",
       "        response: {\n",
       "          action: 'append',\n",
       "          file: file.name,\n",
       "          data: base64,\n",
       "        },\n",
       "      };\n",
       "\n",
       "      let percentDone = fileData.byteLength === 0 ?\n",
       "          100 :\n",
       "          Math.round((position / fileData.byteLength) * 100);\n",
       "      percent.textContent = `${percentDone}% done`;\n",
       "\n",
       "    } while (position < fileData.byteLength);\n",
       "  }\n",
       "\n",
       "  // All done.\n",
       "  yield {\n",
       "    response: {\n",
       "      action: 'complete',\n",
       "    }\n",
       "  };\n",
       "}\n",
       "\n",
       "scope.google = scope.google || {};\n",
       "scope.google.colab = scope.google.colab || {};\n",
       "scope.google.colab._files = {\n",
       "  _uploadFiles,\n",
       "  _uploadFilesContinue,\n",
       "};\n",
       "})(self);\n",
       "</script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sample.mp3 to sample.mp3\n"
     ]
    }
   ],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqkNShKJjmsB",
    "outputId": "1b97a2c7-028b-4fb0-8bf6-f9230b6a5935"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/whisper/generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß Transcript:\n",
      "  Worrying us that should fight it you're no nearer here. It's trance step in which you know shipping a second sword to natural every point in pilot and bends that\n"
     ]
    }
   ],
   "source": [
    "transcript = transcribe_audio(\"sample.mp3\")  # change if your file has a different name\n",
    "print(\"Transcript:\\n\", transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436,
     "referenced_widgets": [
      "7c007fe08645407db61b8b8326fa914e",
      "cf4a13b67e3d4cdfa3af31081d4356a6",
      "0f8e1a35766d447eb922828bb0e70a06",
      "4ed69467adc14e17a859b1394e71039e",
      "eecbb172799f4e0a806e81ac80146601",
      "53caab68081348e991d1927e1b1cc56a",
      "520833adcb564d6f8f28111cdb95e710",
      "17b8051429ec45a7b1d012df90438c2f",
      "ec584709ea7c4d648a3f24140771801c",
      "26f56576d0a04c9aa0b1bdf0873758e1",
      "df95b6393365453ebf6dc9b0f4a3e23a",
      "93c0a5bf9ddb45d29058fe557f59d375",
      "ac0315e3f38242d081297e19f6636e3f",
      "9d002ca72e1b4271a6cf4d1bed6dcc05",
      "a9c26551e5fc4d83bb672873e17a3448",
      "c7b5ccf4f3eb45ed8a6f43c2f06ea316",
      "5897df5562894cbaba1b7a33ebad0182",
      "2280fcdc784a4384bf4eb14644a60b01",
      "6ba0bd4040c4461bb6fd626549f5ad86",
      "a0064ac88a84451ba15cb3efcf9cbdfa",
      "92f62067ce354836862dac2e5226785e",
      "cbbde0b5910c449b8eeed7535921ed4e",
      "0b709542c77a40b2a787959fdc8964d6",
      "7d2ef5529dba4e419d7cad8ebcc55661",
      "12e33e977d2640a4a7703f50d12373c2",
      "a3c98e3b053245c0bdb6e15ed6264c61",
      "10435f7c2c25411cae97dd9721846a7e",
      "d4c280136a294429b30d8c1179772341",
      "fc38fc39af73468bbdbedf258986e88c",
      "a9eade0982264f1f8fc24dd762941a6a",
      "8062896c6dcc4a2385e1f9415b5c18a8",
      "04b4b860c591457e8ddd63052f6bacd0",
      "f856e8db835a40938d79e9f4454153d1",
      "b02a415516b24006b8edeef87289a600",
      "192ea2ab6a86449f98175c28abc94ee9",
      "2f5d6a6b8fda497dbf3a86e65f1b9b7b",
      "9d115b64fc2640918aab24efffe3c35e",
      "35dcd39921294492a7cb8e6853236b4f",
      "cb3be7875fba47f49263fc232bece9cf",
      "9e615b5d49dd41db81e5fefaf0a9d117",
      "028e6c4457784bc0a0eb6a6670ae4596",
      "3a7f2190ba2c4c9a964e737ee908c946",
      "85d1122ca5784b8b952e803480977951",
      "b650c61117fd4da0b048759b7cbdd837",
      "69af83106821455eac9fc3c69c158cf3",
      "343b9998f48e44cc99b3f5fd8ded8f7b",
      "16c24eb69555472ebbc41817d2d928b8",
      "7c7614829fb54429a72e69a24170b096",
      "edaff113b9a74c1b8b5dee716766df12",
      "e9d64a69730645749b349f4aa79ed839",
      "43abbe75729d423fb7cead9cf768c70a",
      "19fb09f77d104e18aad953e7fad23c38",
      "377b95860e2342aa8432e06deafc710b",
      "f20f44b7ffac43368fe059a3dde75e4e",
      "5c2986b37717428994e780b117f9c6b1",
      "d18945ba2961494fbd642ec4883e9495",
      "1f92bb8cae9846669fbc8eef754a7c14",
      "1091e98834ec4a54ae8258a2e4b6b8d2",
      "3fe99d650dde4515a6e808a283fa7429",
      "e94500874d2f46f796de0079651c3da3",
      "ff99564265f9442faac679b4cba55d25",
      "0913aecfaf0d45669efc8e533e5bd786",
      "6bb632ca14c64ec8a7407dec4760b33d",
      "54f22f759aec4ee0b2c6f677e80dcbb1",
      "cac08110b7764e0f9f6b5e8a6ffecaf1",
      "61ce385b5f194b6385741b5c6ced91d9",
      "038fbefca32b40faa54a6c796078bae5",
      "42145bfebf7b41e98f51414f0f5425fc",
      "60dde7d5d27a4d18aa1020e8f6468b9f",
      "1a8ddc9b886a4dff806eece89b70b37e",
      "5ec6c316bff14a11ae3340fe52073ab4",
      "7d1507c8e6b54c39890f91dd116fce49",
      "7b3a22cdb0bd4bdea64bc51fa8e71338",
      "2b477f9e4e2c40208d9fc30ce1f7e6ed",
      "b79e70cd21394cca94715dca41aed0ce",
      "884e1d8bfbfa4f9fa1b1c40470c341ed",
      "e978ef68c65742bcaddeb189487a5d0d",
      "9966cbbf421e4877a01ce57a6fd089f5",
      "85621acb738e40c2b365d575ef00b641",
      "b6233380b83744708d09c5318db66afe",
      "64376e3f61cc46b7adad178b4d124549",
      "f18bc87954474029bba146f39b096913",
      "1a422ab005f8423cb15eef7092239ea0",
      "55a3846663fe4f01ba88f352a3234e50",
      "20a5151b5c474392ad99c9a036bd8045",
      "e0fae2fa94c742c08d858fcc91c06621",
      "94f45666c07544ae827858229de05625",
      "98184b73758b44f9a31358a43640084b",
      "b091dea02d5d49bebf92cd8aaccd6624",
      "40f5797f870e40c7b79408d5f54fdc81",
      "ff7121a503e04f17999fba8f663dd357",
      "aadca742966742cdb182804cbfcd16c1",
      "c320f0d762f74728bc2a9df4935eeaf1",
      "82a4edb603b04139b56819b8da13de5e",
      "bcac5b3a5242488e82db6b949bbc122c",
      "9b814461bb494d9ea4cb59e82bf71e12",
      "51543f45e8644b23808f81dbbd36ae87",
      "c720be80d16043408abcebb82b0113e8",
      "038c4fbc35014f96a5126c408d39aebe",
      "a58fa8fee1b84ac082994bfd38071b17",
      "734f9b835a3f41809e770cc17c26220b",
      "a4c8f72dd196403cb18e338f9b8ef3de",
      "a87889446b12430b8fb4e234b6610887",
      "88e5d3d0f0d84a6bbeed1b64c6fd8a10",
      "cda8a0d4f0fc4181b20c90dd21ca07b6",
      "85674c48550746e383f3bbe4bd96d454",
      "d19f1e3b4390483e83efdedd10c0321d",
      "c306cef25bfd42339415a5ad7fd14330",
      "1d7ee4eb89fd48aaa81995b364e93464",
      "8b7bbfaaa874446fae23400d0900e28f",
      "22f1105c777747ef839d340a2f4bafa2",
      "d86e3ed5b5ec4c5cb1ab5905d25889a4",
      "69cf781c4d134f6dae3878b747114966",
      "5eea0c0f367e414a9304e56bbc2c8273",
      "65b4ee5a4e6d41debf1f963f4c4d4b62",
      "ed783776a2bf4e0a920af8b07c474251",
      "7cddba580ec74c139fde24e5058fcb84",
      "d1d0f5db93564c2991d40d19f426b963",
      "f33acb9f5ddf457a8547ab5bdbb4311d",
      "7604daef0c964ed1a85f8d51d85aeab7",
      "beb6eb56ab0f4799a233062099c5892b",
      "49a999fac3b240488a98e57a7ae89b18",
      "593802e5fa2d4639817e680160b3bad2",
      "9e2e9563c1e24f749e51c6f454bc2284",
      "dd16cd87958c4af7b0e5f62815b1db7a",
      "41bb838ac8994efebec0bcf5413ff0f1",
      "59fb74ba750643838c66b40fd85e5c29",
      "bb93d7d61f134ffa9d61afe859481d71",
      "b524721c88704a77b9df569c776865da",
      "24a62183a8264bdea441740abadf53d1",
      "b8a0597591d84b7b8c47503ba7989d19",
      "c1d4aecc4f9740e581b8d3efa9c78d5a",
      "be2e361d1560455e8bcd749af18ee983",
      "158e2270f604489498e66eb98875b429",
      "1423eb00a15e46208433819e525643ee",
      "f511acb708514e5d9f0afad1929d6394",
      "6b5c7f52394147069608050d090968d9",
      "3ff6d859a8df4cfc9e2386ae38872738",
      "7735dec67b1a4970ac25d7f9b57568f3",
      "be40e6858f694de0ae5719353f70f7f0",
      "4aeafc2e53aa4d5bb553f68a18b22069",
      "707923dd30f347698509debe3de19d31",
      "d4421127043c4afa9dc50f014e0e0773",
      "54f18ce11306471c81301341f24b3104",
      "f87688da41ad4598981bb9b6dc3e8ab2",
      "f6d03dcbbcfd49cdb4576db808654dc1",
      "3b750bbc19c24c43880e40819be1d99b",
      "41df1f406b0840d4a0c5d2b4b7b912a4",
      "9798a31a92e54f88965a533e153de601",
      "dcf030ad65904d38ba44ea85ba16c431",
      "09cc3e2cd66f4d45b3173eeb02d0852f",
      "19fc0f60c9d546a79cbff164fb15c0dd",
      "4b879f96932742c5b598998ace23d6d8"
     ]
    },
    "id": "P1uJLimkkfie",
    "outputId": "2b87067d-2c41-4885-d4f5-139608b644e6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c007fe08645407db61b8b8326fa914e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2280fcdc784a4384bf4eb14644a60b01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc38fc39af73468bbdbedf258986e88c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e615b5d49dd41db81e5fefaf0a9d117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43abbe75729d423fb7cead9cf768c70a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0913aecfaf0d45669efc8e533e5bd786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3a22cdb0bd4bdea64bc51fa8e71338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a3846663fe4f01ba88f352a3234e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcac5b3a5242488e82db6b949bbc122c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85674c48550746e383f3bbe4bd96d454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cddba580ec74c139fde24e5058fcb84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb93d7d61f134ffa9d61afe859481d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "import os\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "\n",
    "\n",
    "login(token=hf_token)\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "\n",
    "summarizer = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "N-0QlU9RmFCu"
   },
   "outputs": [],
   "source": [
    "def format_prompt(transcript):\n",
    "    return f\"\"\"\n",
    "You are an expert meeting assistant. Based on the transcript below, generate:\n",
    "\n",
    "1. A concise summary of the discussion\n",
    "2. A list of 3‚Äì5 action items\n",
    "3. Any important decisions made\n",
    "\n",
    "Transcript:\n",
    "\\\"\\\"\\\"{transcript}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "def summarize_transcript(transcript):\n",
    "    prompt = format_prompt(transcript)\n",
    "\n",
    "    response = summarizer(prompt, max_new_tokens=512, do_sample=True, temperature=0.7)\n",
    "    return response[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TsTQ18r-mIsw",
    "outputId": "2c9c19e9-e86e-46aa-b204-cf327b3e72fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Summary:\n",
      " \n",
      "You are an expert meeting assistant. Based on the transcript below, generate:\n",
      "\n",
      "1. A concise summary of the discussion\n",
      "2. A list of 3‚Äì5 action items\n",
      "3. Any important decisions made\n",
      "\n",
      "Transcript:\n",
      "\"\"\" Worrying us that should fight it you're no nearer here. It's trance step in which you know shipping a second sword to natural every point in pilot and bends that\"\"\"\n",
      "\n",
      "Summary:\n",
      "This meeting is a discussion about a problem concerning a second sword that is being shipped to a natural point in pilot. The participants are concerned about the delay in the delivery and the possibility of it not being shipped.\n",
      "\n",
      "Action Items:\n",
      "\n",
      "1. Investigate the cause of the delay in the shipment of the second sword.\n",
      "2. Determine the exact delivery date of the second sword.\n",
      "3. Ensure that the second sword is properly packaged and labeled for shipping.\n",
      "4. Follow up with the shipping company regularly to monitor the progress of the shipment.\n",
      "5. Have a backup plan in place in case the second sword is not delivered on time.\n",
      "\n",
      "Important Decisions:\n",
      "No important decisions were made in this meeting.\n"
     ]
    }
   ],
   "source": [
    "summary = summarize_transcript(transcript)\n",
    "print(\"Summary:\\n\", summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SJE0MBvqp832",
    "outputId": "0800dea0-0b73-4f1d-e606-47e38c649b1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reportlab\n",
      "  Downloading reportlab-4.4.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from reportlab) (11.2.1)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from reportlab) (5.2.0)\n",
      "Downloading reportlab-4.4.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: reportlab\n",
      "Successfully installed reportlab-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WROapKaTqBJp"
   },
   "outputs": [],
   "source": [
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.pdfgen import canvas\n",
    "import datetime\n",
    "\n",
    "def generate_summary_pdf(summary_text, output_path=\"meeting_summary.pdf\"):\n",
    "    \"\"\"\n",
    "    Generate a PDF from a summary string.\n",
    "    \"\"\"\n",
    "    c = canvas.Canvas(output_path, pagesize=A4)\n",
    "    width, height = A4\n",
    "    c.setFont(\"Helvetica\", 12)\n",
    "\n",
    "    # Title\n",
    "    c.drawString(40, height - 40, \"üìÑ Meeting Summary\")\n",
    "    c.setFont(\"Helvetica\", 10)\n",
    "    c.drawString(40, height - 60, f\"Generated: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "\n",
    "    # Content\n",
    "    text = c.beginText(40, height - 100)\n",
    "    text.setFont(\"Helvetica\", 11)\n",
    "\n",
    "    for line in summary_text.split(\"\\n\"):\n",
    "        if text.getY() < 40:\n",
    "            c.drawText(text)\n",
    "            c.showPage()\n",
    "            text = c.beginText(40, height - 40)\n",
    "            text.setFont(\"Helvetica\", 11)\n",
    "        text.textLine(line.strip())\n",
    "\n",
    "    c.drawText(text)\n",
    "    c.save()\n",
    "    return output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aHfFA4UAqEI7",
    "outputId": "76f147f0-8c2f-4298-ae9a-8caad9679513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ PDF saved at: meeting_summary.pdf\n"
     ]
    }
   ],
   "source": [
    "pdf_path = generate_summary_pdf(summary)\n",
    "print(\"PDF saved at:\", pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "TL9PIUxYqG7c",
    "outputId": "e295b1c9-2fa5-4a2f-f0c8-5c3bda42f646"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_513ac272-1910-4280-9efe-b934b74ff86d\", \"meeting_summary.pdf\", 2297)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from google.colab import files\n",
    "files.download(pdf_path)"
   ]
  }
 ],
  "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPMpVb/i64GGVEPv7t+7Av2",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
